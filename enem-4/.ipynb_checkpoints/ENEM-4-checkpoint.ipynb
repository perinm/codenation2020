{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.over_sampling import (RandomOverSampler,ADASYN,BorderlineSMOTE,\n",
    "                                    KMeansSMOTE,SMOTE,SVMSMOTE)\n",
    "\n",
    "from imblearn.under_sampling import (RandomUnderSampler,CondensedNearestNeighbour,\n",
    "                                     EditedNearestNeighbours,\n",
    "                                    RepeatedEditedNearestNeighbours,\n",
    "                                    NeighbourhoodCleaningRule,AllKNN,TomekLinks)\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_predict(df,func):\n",
    "    resampling = func()\n",
    "    model = XGBClassifier()\n",
    "    pipeline = Pipeline([('Resampling', resampling), ('XGBClassifier', model)])\n",
    "    X=df.drop(\"IN_TREINEIRO\",axis=1)\n",
    "    y=df.IN_TREINEIRO\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,stratify=y,random_state=42)\n",
    "    pipeline.fit(X_train, y_train) \n",
    "    predicted = pipeline.predict(X_test)\n",
    "    print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(df,model,submit=False):\n",
    "    if submit:\n",
    "        X, y = df.drop(\"IN_TREINEIRO\",axis=1),df[\"IN_TREINEIRO\"]\n",
    "        model.fit(X,y)\n",
    "        return model\n",
    "    if \"IN_TREINEIRO\" in df:\n",
    "        X, y = df.drop(\"IN_TREINEIRO\",axis=1),df[\"IN_TREINEIRO\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=42)\n",
    "        model.fit(X_train,y_train)\n",
    "        predicted = model.predict(X_test)\n",
    "        print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "        print('Confusion matrix:\\n', confusion_matrix(y_test, predicted))\n",
    "        return model\n",
    "    else:\n",
    "        return model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_modcat(df,ct=None):\n",
    "    anom_columns = [\"NU_INSCRICAO\",\"CO_UF_RESIDENCIA\"]\n",
    "    cat_variables = [\"SG_UF_RESIDENCIA\",\"TP_SEXO\",\"Q001\",\"Q002\",\"Q006\",\"Q024\",\"Q025\",\"Q026\",\"Q027\",\"Q047\"]\n",
    "    num_variables = [\"NU_NOTA_COMP1\",\"NU_NOTA_COMP2\",\"NU_NOTA_COMP3\",\"NU_NOTA_COMP4\",\"NU_NOTA_COMP5\",\n",
    "                     \"NU_NOTA_REDACAO\",\"NU_NOTA_CN\",\"NU_NOTA_CH\",\"NU_NOTA_LC\"\n",
    "                    ]\n",
    "    df.drop(anom_columns,axis=1,inplace=True)\n",
    "    return pd.get_dummies(df, columns=cat_variables, drop_first=True)\n",
    "    #Testa se estamos com dataframe de treino ou de teste\n",
    "    if \"NU_NOTA_MT\" in df.columns:\n",
    "        for col in num_variables:\n",
    "            col_tratar = df1[col]\n",
    "            media = col_tratar.mean()\n",
    "            std = col_tratar.std()\n",
    "            df1[col] = (col_tratar-media)/std\n",
    "        return df1\n",
    "    else:\n",
    "        return pd.DataFrame(ct.transform(df1),columns=df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13730 entries, 0 to 13729\n",
      "Columns: 167 entries, Unnamed: 0 to Q050\n",
      "dtypes: float64(28), int64(79), object(60)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['NU_INSCRICAO', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA', 'NU_IDADE', 'TP_SEXO', 'TP_COR_RACA',\n",
    " 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\"IN_TREINEIRO\",\n",
    " 'TP_DEPENDENCIA_ADM_ESC', 'IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DISLEXIA', 'IN_DISCALCULIA',\n",
    " 'IN_SABATISTA', 'IN_GESTANTE', 'IN_IDOSO', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC',\"TP_PRESENCA_MT\",\n",
    " 'NU_NOTA_CN', 'NU_NOTA_CH',\n",
    " 'NU_NOTA_LC', 'TP_LINGUA', 'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3',\n",
    " 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'NU_NOTA_REDACAO', 'Q001',\n",
    " 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q027', 'Q047']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum = drop_modcat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3584\n",
      "           1       0.98      0.98      0.98       535\n",
      "\n",
      "    accuracy                           0.99      4119\n",
      "   macro avg       0.99      0.99      0.99      4119\n",
      "weighted avg       0.99      0.99      0.99      4119\n",
      "\n",
      "Confusion matrix:\n",
      " [[3575    9]\n",
      " [  12  523]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino(df_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomUnderSampler\n",
      "\n",
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3584\n",
      "           1       0.92      0.99      0.95       535\n",
      "\n",
      "    accuracy                           0.99      4119\n",
      "   macro avg       0.96      0.99      0.97      4119\n",
      "weighted avg       0.99      0.99      0.99      4119\n",
      "\n",
      "Confusion matrix:\n",
      " [[3538   46]\n",
      " [   5  530]]\n",
      "\n",
      "RandomOverSampler\n",
      "\n",
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3584\n",
      "           1       0.97      0.98      0.98       535\n",
      "\n",
      "    accuracy                           0.99      4119\n",
      "   macro avg       0.98      0.99      0.99      4119\n",
      "weighted avg       0.99      0.99      0.99      4119\n",
      "\n",
      "Confusion matrix:\n",
      " [[3569   15]\n",
      " [  10  525]]\n"
     ]
    }
   ],
   "source": [
    "under = [\"RandomUnderSampler\"]\n",
    "over = [\"RandomOverSampler\"]\n",
    "for model in under:\n",
    "    print(\"\\n\"+model+\"\\n\")\n",
    "    sampling_predict(df_dum,eval(model))\n",
    "for model in over:\n",
    "    print(\"\\n\"+model+\"\\n\")\n",
    "    sampling_predict(df_dum,eval(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = treino(df_dum,submit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_dum1 = drop_modcat(df_test.copy())\n",
    "preds = treino(df_dum1,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.Series(preds,name=\"IN_TREINEIRO\")\n",
    "df_entrega = pd.concat([df_test.NU_INSCRICAO,z], axis=1)\n",
    "df_entrega.to_csv(\"answer.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
